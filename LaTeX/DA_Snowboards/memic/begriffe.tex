\chapter{Überblick über die Materie}

// es fehlt eine Einleitung

\section{Performance Optimierung}

Die Performance Optimierung lässt sich allgemein als der Prozess der Verbesserung einer getätigten Leistung beschreiben. Mit dieser Definition lässt sich ein schnellerer Weg von Punkt A zu Punkt B als eine Weg-Zeit Optimierung darstellen. In der Computer Technik beschreibt die Performance Optimierung daher grundsätzlich, dass ein Computer System oder eine Computer Software in bestimmten Bereichen effektiver bzw. mit weniger Rechenleistung läuft. Für Computerspiele ist die Performance Optimierung ein essenzieller Teil der Spiele-Produktion vor der Veröffentlichung. Code, In-Game Physics, Game-Assets und allgemeine Grafik Optimierung bilden damit den Überbegriff: Performance Optimierung. Dies erklärt dennoch nicht deutlich genug, was genau die Optimierung von 3D-Assets bedeutet und wird im Folgenden konkret erklärt.\cite[648]{_advances}

\subsection{Was ist schlechte Performance?}

Schlechte Performance ist eindeutig erkennbar und kann in Spielen in zahlreichen Formen auftreten. Die gewöhnlichsten Formen davon sind eine niedrige Framerate, Standbilder, lange Ladezeiten, Abstürze und Fehlermeldungen, Grafikfehler, inkonsistente In-game-Physik, falsches Benehmen von Spiel-Ereignissen und auch hoher Strom verbrauch.

\subsection{Was löst schlechte Performance aus?}

Ein Videospiel ist nichts weiter als eine Tätigkeit, welche vom Computer getätigt werden muss und folglich auch Rechenleistung nutzen muss. Die CPU (= Central Processing Unit) und GPU (= Graphics Processing Unit) benötigen Ressourcen, um Prozesse auf dem Computer laufen zu lassen. Genauso ist auch der RAM (=Random Access Memory) zu beachten. Die Überlastung dieser Komponenten führt daher zu verschlechterter Performance. Es ist wichtig anzumerken, dass die Überlastung sowohl durch die Entwickler als auch durch die Nutzer entstehen kann. Spiele können nur bis zu einem gewissen Grad auf eine bestimmte Mindestanforderung optimiert werden, wenn jedoch der Computer zu einer veralteten Generation angehört, wird jegliche Optimierung sinnlos sein. Die Entwickler sind zuständig für alle ausgeführten Prozesse während der Laufzeit des Spiels und deswegen in vielen Instanzen hauptverantwortlich für ein schlecht laufendes Spiel.

\section{Rendering \& die VR Kamera}


\subsection{Rendering}

Rendering ist ein Fachausdruck aus der Computer Grafik. Rendering umschreibt jenen technischen Prozess, mit welchem die GPU  und CPU durch Rohdaten ein Bild auf einem Bildschirm generiert. Rendering ist daher Grund, weshalb unser Computer während der gesamten Laufzeit ein Bild darstellen kann. Daraus folgt, dass jedes 3D-Assets und ebenso jedes Spiel mittels Rendering ein Bild anzeigt. In Spielen und 3D-Modeling wird zwischen zwei wichtigen Arten von Rendering unterschieden:
Real-Time Rendering: Hier handelt es sich um alle Rendering-Prozesse, in Echtzeit (Realtime) bzw. während der Laufzeit berechnet werden und deswegen für interaktive Ereignisse nützlich sind.
Offline-Rendering ist das Gegenstück zum Real-Time-Rendering. Hierbei wird ein Bild vorzeitig fertig berechnet und erspart während der Laufzeit einiges an Leistung.
Wie bereits erklärt, kann ein Spiel ohne Rendering kein Bild ausgeben. Damit ein Bild ausgegeben werden kann, wird in Game-Engines, wie die Unity-Engine, eine virtuelle Kamera benötigt. Diese virtuelle Kamera ist schlussendlich die Perspektive , aus welcher Nutzer das Spiel erleben werden. Die Perspektive kann von Spiel zu Spiel variieren und bestimmt die Stimmung und das Erlebnis des Spieles. Der tatsächliche Rendering-Prozess ist dabei nicht abhängig von der Kamera und bleibt in den meisten Umständen gleich.
Es ist wichtig anzumerken, dass die Anzahl der aktiven Kameras in der Game-Szene die Anzahl an einzelnen Rendering-Prozessen erhöht. Jede aktive Kamera muss mittels CPU und GPU gerendert werden und erhöht dabei die Rechenlast.
Als Beispiel nehmen wir eine Unity-Szene, in welcher sich drei Objekte und zwei Kameras befinden, die aus unterschiedlichen Winkeln auf die Objekte zeigen. Obwohl es sich immer noch um drei Gegenstände in jeder Kameras handelt, müssen alle Objekte aus jeder Kamera gerendert werden, weswegen nun 6 Objekte gerendert werden müssen.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/UnityExample}
	\caption{Rendering Beispiel: 2 Kameras in Unity}
\end{figure}

\subsection{VR-Kamera}

Der Zweck von Virtual Reality ist es, einen möglichst immersiven Raum darzustellen. Die VR-Brille besitzt zwei Linsen, durch welche der/die Träger/in das virtuelle Bild wahrnehmen. Die VR-Kamera muss dafür genauso rendern. Damit es sich jedoch nicht um ein statisches zweidimensionales Bild handelt, ist es unentbehrlich, dass die Szene mittels zwei Kameras aus unterschiedlichen Winkeln aufgenommen wird. Die VR-Linsen simulieren damit die Augen eines Menschen, um das Gefühl eines wirklichen Raumes zu realisieren. Pro Linse wird jeweils eine Kamera benötigt, woraus sich erhöhte Rendering-Kosten ergeben. Eine Unity-Szene mit integriertem VR-Headset muss deswegen die gesamte Szene doppelt rendern. VR-Technologie stellt damit ein großes Performance-Bottleneck für Entwickler dar, weswegen sich der Markt nur langsam verbreitet. Realistische oder detaillierte Szenen sind mit effektiver Optimierung der 3D-Assets dennoch möglich.
\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/VR_view}
	\caption{VR-Sicht mit zwei Linsen}
\end{figure}
\cite{_vrview}

\section{Mesh Optimierung}

Game-Assets lassen sich mit den Requisiten in Filmen vergleichen. Assets beziehen sich auf jene digitale bzw. virtuelle Gegenstände, welche für die Spielentwicklung benötigt werden. Hierzu gelten zweiD Art und 3D Models, Animationen oder Audiofiles. Die 3D-Assets werden von 3D-Artists erstellt und in das Spiel importiert. Hier kann es sich um jeden möglichen Gegenstand, wie bspw. eine Tasse oder ein Charakter handeln.

\subsection{Das Mesh}

3D-Assets auch Mesh Objekt ist ein vom Computer generiertes Polygonnetz. Ein Polygon setzt sich aus mehreren Polytopen (Punkten) und den damit entstehenden Streckenzug (Kanten) zusammen welche dann das Vieleck bilden. Beim Polygonnetz handelt es sich somit um eine Anreihung zahlreicher Polygone nebeneinander, welche gemeinsam die Geometrie des Mesh bilden. Ein Polygon muss aus mindestens drei Polytopen bestehen, um eine geschlossene Fläche zu bilden. Damit stellt das Dreieck die einfachste Variante eines Polygons dar.\cite{_the_essential_guide_to_3D}

\subsection{Geometrie vs. Topologie}

Ein Mesh kann auf zwei verschiedene Arten betrachtet werden: Geometrie und Topologie. Diese zwei Begriffe werden oft verwechselt, doch beschreiben sie andere Eigenschaften des Meshes. Die Geometrie eines Meshes beschreibt den Körper als Gesamten. Das bedeutet, dass die Geometrie die Form und Maße des Objektes umfasst. Bei der Topologie spricht man von der Struktur eines Meshes. Ein Mesh kann bspw. zweimal in derselben Form existieren, würde sich aber in seiner Struktur unterscheiden. Diese Struktur bezieht sich dabei auf die Anordnung seiner Vertices, Edges und Faces und wie die Komponenten miteinander verbunden sind.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/topology_geometrie}
	\caption{Unterschied zwischen Topologie und Geometrie\cite{_geoTopo}}
\end{figure} 

In Essenz besteht das Mesh aus 3 wichtigen Komponenten\cite[2]{_highpoly_to_lowpoly}:

\subsubsection{Vertex (Mehrzahl Vertices)}

 Ein einzelner Punkt (= Polytop)
Sie stellen einen Punkt dar und werden mittels Vektors beschrieben. Damit können die Koordinaten des Punkts in einem Koordinatensystem angegeben werden.\cite[S.47]{_the_essential_guide_to_3D}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Vertices_Example}
	\caption{Visuelle Darstellung von Vertices}
\end{figure}

\subsubsection{Edge}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Edges_Example}
	\caption{Visuelle Darstellung von Edges}
\end{figure}

Es entsteht aus 2 Punkten und bildet damit eine Linie/Kante
//vielleicht noch mehr Ausarbeitung

\subsubsection{Face (Polygon)} 

Es besteht aus mindestens 3 verbunden Edges, die eine Fläche bilden.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Faces_Example}
	\caption{Visuelle Darstellung von Faces}
\end{figure}

\subsection{Tris, Quads und N-Gone}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Polygons}
	\caption{Tri, Quad \& N-Gon}
\end{figure}

Streng genommen gibt es kein Maximum an Edges und Vertices, die ein Face besitzen kann. Jedoch sind zwei Arten von Polygonen besser geeignet als andere. Hierbei spricht man fachlich von Quads (Vierecken) und Tris (Dreiecken). Überschreitet ein Face die Anzahl an Vertices eines Quads, also vier Vertices, spricht man von einem N-Gon. N-Gone unterscheiden sich vom Rendering-Prozess nicht von allen anderen Polygonen, jedoch führen N-Gone meist zu irritierenden Rendering-Ergebnissen und anderen grafischen Fehlern. Weitführend sie die meisten 3D-Softwares nicht darauf ausgelegt, mit N-Gonen zu arbeiten, da der Workflow in 3D-Modeling Programmen auf optimierte Topologie basiert.
Bevor ein Mesh exportiert wird, wird die Topologie des Mesh meist aus Quads bestehen, da das Model bei notwendigen Veränderungen leichter bearbeitbar ist. Sobald das Asset in die Game-Engine importiert wurde, konvertiert die Engine jegliche Quads zu Tris. Dies liegt daran, dass jedes Quad in zwei Tris aufgeteilt werden kann. Der Vorteil beim Rendering dabei ist, das die Fläche eines Dreiecks planar ist, im Gegenzug zu dem eines Quads. Dies bietet den Vorteil, dass nur die einfachste geometrische Fläche gerendert werden muss und damit auch den Vorteil, dass keine Probleme beim Shading des Models vorkommen.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Ngon_Shading}
	\caption{Shading-Probleme bei N-Gonen}
\end{figure}

\subsection{Die Wichtigkeit von Performance Optimierung in Video Spielen}

"`The goals of performance optimization are deeply entwined with user experience. Poorly optimized games can result in low frame rates, freezes, crashes, input lag, long loading times, inconsistent and jittery runtime behaviour, physics engine breakdowns, and even excessively high battery power consumption (an often-neglected metric for mobile devices). Having just one of these issues can be a game developer's worst nightmare as reviews will tend to focus on the one thing that we did poorly, ignoring all the things that we did well."'\cite[S. 17]{_unity_game_optimization}

\subsection{Beispiel: Cyberpunkt 2077}

Cyberpunk 2077 dient als ein gutes Beispiel für die Konsequenzen von schlechter Performance. Vor dem Veröffentlichen war das Spiel eines der meisterwarteten Spiele von 2020. CD Project RED, die Entwickler des Titels versprachen eines der größten Open-World-Action-Rollenspiele, das je auf den Markt kommen würde. Dabei wurde sehr viel Wert auf die visuelle Qualität des Spieles gelegt, da das futuristische Aussehen ein wichtiger Teil des Marketings war. Die Stadt, in welcher sich die Spieler aufhalten, ist dabei äußerst detailliert und befüllt mit unterschiedlichen Aktivitäten, Autos, Charakteren, Waffen und weiteren Assets welche dem Spiel sein einzigartiges Aussehen geben. Das Spiel verfügt über zahlreiche Grafikeinstellung als auch die Option Raytracing zu verwenden. Ein weiteres Ziel der Entwickler war es keine Art von Ladebildschirm während dem Spielen zu haben. Dies Bedeutet das Tausende von Assets konstant berechnet werden müssen. Cyberpunk 2077 ist 70 Gigabyte groß und ist damit ein sehr rechenintensives Spiel. Ob das Spiel in einem guten Zustand laufen würde, ließ sich erst nach der Veröffentlichung klar sagen. Das Spiel sollte 2020 am 19. Dezember für Microsoft Windows, Playstation 4, Xbox One, GeForce Now und Google Stadia erscheinen. Hierbei waren die ersten Rezensionen geplagt von Performance Problemen auf allen erschienenen Geräten. Zahlreiche Windows Nutzer konnten trotz der richtigen Systemanforderung das Spiel nicht flüssig spielen.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Cyberpunk2077}
	\caption{Spiel Screenshot beim Launch}
\end{figure}

 Es gab zahlreiche grafische Probleme und Fehler als auch konstante FPS-Einbrüche. Dies betraf vor allem Konsolenspieler auf der Xbox One und der Playstation 4. Das Spiel war nach ihrem Kauf für viele Käufer nicht spielbar, was zu sofortigen Rückgabe von über dreißigtausend Kopien führte. Weiters entschied sich Sony Cyberpunk bis 21.Juni 2021 aus dem Sony Playstation Store zu entfernen.
 
\begin{figure}[H]
		\centering
"`Cyberpunk 2077’s disastrous launch led to very few refunds, according to CD Projekt Red CFO Piotr Nielubowicz, who shared details on the situation during an earnings call with investors. The dystopian cyberpunk RPG sold 13.7 million copies, but the developer only issued 30,000 refunds"'
\end{figure}
\cite{_cyberpunkArticle}

Cyberpunk 2077 beweist das Erlebnis der Spieler auf einem technischen Niveau stark von der Performance Optimierung abhängt.

\subsection{Fragestellung}

Abgesehen vom tatsächlichen Gameplay und seinen Mechanics braucht ein Spiel Art und Assets, um seine eigene Identität zu definieren. Spiele sind deswegen mit visuellen Assets überflutet, um die Immersion der Spieler zu verstärken. Daraus folgt eine gigantische Anzahl an Mesh-Objekten, Texturen, Partikeln, Sprites und zahlreichen anderen Komponenten, die einen Großteil der Performance beanspruchen. Wie gelingt es Spieleentwicklern trotz des hohen Anspruches an grafischen Details, Realismus oder Umfang an Inhalt eine stabil laufende Experience zu kreieren?

\subsection{Mesh Resolution}

Anders, als wie bei der Auflösung eines 2D Bildes geht es bei Mesh-Objekten nicht um die Anzahl der Pixel. Jedoch geht es in beiden Fällen um den sichtbaren Detailgrad. Im Falle von einem Mesh bezieht sich die Resolution um das Detail der Topologie. Wie bereits in Geometrie vs. Topologie klargestellt, handelt es sich bei der Topologie um die Anordnung der Faces. Die Auflösung bedeutet im Kontext eines 3D-Assets, wie viele Faces ein bestimmtes 3D-Mesh besitzt. Eine wichtige Grundregel für jedes Asset ist klarstellen, von welcher Wichtigkeit es ist. Assets, mit welchen die Spieler konstant interagieren oder im Verlaufe des Spieles häufig sehen, sollten den größten Detailgrad im Spiel besitzen, da hier ein Mangel an Qualität und Auflösung deutlich sichtbar ist. Die Auflösungen eines Assets spielt dabei eine große Rolle für die Performance in Spielen. Die Unity-Engine nimmt jegliche Assets so an, wie sie importiert werden, obgleich die Auflösung des Objektes notwendig ist. Das bedeutet, dass jedes existierende Face gerendert wird und damit sofortige Konsequenz für die Performance hat.\cite[16]{_3d_modeling_pipline}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/HighLow}
	\caption{Mesh Resolution eines Assets}
\end{figure}
\cite{_meshResolution}

\subsection{Mesh Cleanup}

„Cleanen“ bedeutet für alle 3D-Assets, dass die momentane Auflösung kleiner wird. Für die Topologie heißt dies, dass die Anzahl an Faces reduziert wird.\cite[S.152]{_unity_game_optimization}Tripple-A Spieleentwickler sind vor allem darauf angewiesen alle ihre Assets zu cleanen. 3D-Objekte, welche mittels Sculpting-Tools entstehen, sind so gut wie immer darauf angewiesen ihre Topologie zu cleanen.\cite[S.14]{_3d_modeling_pipline} Hier spricht man auch von der Retopologie. 3D-Softwares bieten unterschiedliche Methoden für die Retopolgie an. Programme wie Autodesk Maya oder Blender besitzen eine integrierte Funktion automatisch das Mesh zu „retopologizen“. Diese Funktion ist allgemein nützlich, die Auflösung zu reduzieren, ist jedoch nicht im Stande einen geeigneten Edgeflow zu generieren.\cite[S.15]{_3d_modeling_pipline} Daher werden besonders wichtige Objekte meist per Hand bearbeitet. 

\subsection{Textur Auflösung und UV-Maps}

Obwohl nicht konkret auf das 3D-Assets bezogen, ist UV als auch Textur Optimierung ein wichtiger Teil der weiterführenden Asset Optimierung. Bei einer Textur handelt es sich um ein 2D-Bild, welches unterschiedliche Informationen beinhalten kann. 
Dabei ermöglicht es mehr Detail auf der Oberfläche eines Objektes darzustellen. Die Textur an sich kann durch unterschiedliche Methoden, wie Photographien, eingescannte Bilder, generierte Bilder oder auch prozedurale Vorgänge erstellt werden. Eine Textur hat dabei unterschiedliche Anwendungsmöglichkeiten und dient nicht immer schlicht für die Einfärbung eines Objektes. Darunter zählen Diffuse oder auch Albedo Maps, Bump Maps, Height Maps, Normal Maps, Metallic Maps, Roughness Maps und andere Arten.\cite[S.18]{_3d_modeling_pipline}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Texture_Example}
	\caption{Textur eines Charakters}
\end{figure}
\cite{_textureExample}

Texturen werden in 3D Programmen und Game-Engines einem Material zugewiesen, welches als Aufgabe hat die Texturen auf das 3D-Mesh zu projizieren. Da die Textur ein Bild ist, hat diese damit auch eine vom 3D-Artist definierte Pixel-Auflösung. Die Auflösung eines Bildes hat damit auch eine Speichergröße. Je höher die Auflösung, je größer die Speichergröße. Um die Speicherkapazität nicht zu überlasten und damit auch nicht Performance, sollte eine angemessene Textur Auflösung gewählt werden.\cite[S.141]{_unity_game_optimization} Kleine Objekte brauchen deswegen keine besonders große Textur.
Eine UV-Map ist ein zweidimensionales Koordinatensystem, welches über die Oberfläche eines Meshes projiziert wird. U und V stellen die beiden Achsen dar und sind notwendig, wenn es darum geht, eine Textur korrekt auf einem Mesh zu übertragen.\cite{_the_complete_guide_to_blender} 3D Softwares ermöglichen den Nutzern mittels unterschiedlicher Tools das Mesh zu UV-Unwrappen. Dieser Prozess „faltet“ die Oberfläche aus und glättet sie, wodurch eine zweiD Fläche entsteht. Die UV-Map dient damit als Bauplan für alle Texturen des Models.\cite[79]{_3d_game_textures}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Texturetypes}
	\caption{Unterschiedliche Arten von Texturen}
\end{figure}
\Cite{_textureTypes}

Die UV-Map besteht dabei nicht aus einer einzigen großen Form, sondern wird meist auf UV-Islands aufgeteilt. Hierbei muss die Skalierung und Anordnung der UV-Islands beachtet werden, da der Platz, den eine Island einnimmt direkt proportional zur Auflösung der Textur ist. Wichtige oder detaillierte Stellen des Meshes sollen deswegen mehr Platz in der UV als andere einnehmen, um Bildauflösung zu sparen.\cite[S.18]{_3d_modeling_pipline}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/UVMap_Example}
	\caption{Beispiel für eine UV-Map}
\end{figure}

\subsection{Texture Atlassing}

\begin{figure}[H]
	\centering
"`Atlasing is the technique of combining lots of smaller, isolated textures together into a single, large texture file in order to minimize the number of materials, and therefore draw calls, we need to use. This is effectively a means to exploit dynamic batching. Conceptually, this technique is very similar to the approaches of minimizing material usage that you learned in Chapter 3, The Benefits of Batching."'\cite[S.145]{_unity_game_optimization}
\end{figure}


Texture Atlasses ist eine Technik, welche für reduzierte Draw Calls und Unity-Batching oft eingesetzt wird. Da dieser Teil außerhalb des Arbeitsbereiches eines 3D-Artists ist, ist der technische Aspekt für die Umsetzung eines Textur-Atlasses irrelevant. Einzig zu beachten ist, dass durch den Textur Atlasse weniger Draw Calls hervorgerufen werden, wovon auch die Performance profitiert.
Die Aufgabe eines Textur-Atlasses ist es, eine Sammlung an kleineren Texturen auf eine einzige größere Textur zu bringen. Diese Technik ist nur dann anzuwenden, wenn alle Materials denselben Shader benutzen. In Essenz werden die einzelnen UV-Islands sämtlicher Objekte auf einer UV-Map organisiert und schließlich texturiert. Hiermit sparen sich die Entwickler einiges an Speicherplatz und können im Falle von kleineren Objekten eine größere Auflösung erhalten. Nachteil dieser Methode ist die spätere Bearbeitung der Textur.\cite[S.146]{_unity_game_optimization}

\subsection{Billboarding}

Ein Billboard (Plakatwand) ist nichts weiter als eine texturierte Fläche. In der Computergrafik ist die Billboarding-Technik eine Methode, um komplexe 3D-Assets zu vereinfachen. Als Beispiel betrachtet man einen Busch. Dieser besteht aus vielen Wurzeln, Zweigen und Blättern. Da ein Busch jedoch in großen Mengen in Spielen auftaucht, ist es unpraktisch ein wirkliches Mesh zu verwenden. Stattdessen wird die Projektion eines Busches oder einfach auch ein Sprite des Busches verwendetet und wird anstelle des Meshes eingesetzt. Damit wird eine immense Rechenleistung gespart, weil dieses Sprite aus nur einem einzigen Face besteht.\cite[48]{_the_essential_guide_to_3D} Da ein Sprite zweidimensional ist, wird es aus bestimmten Blickwinkeln nicht sichtbar sein. Hier kommt das eigentliche Billboarding ins Spiel. Dabei wird zwischen zwei Methoden unterschieden.
Die erste Methode benötigt ein einziges Billboard, welches sich immer in Richtung der Kamera rotiert, um seine Vorderseite anzuzeigen.
Die zweite Methode verwendet mindestens zwei Sprites, welche sich überkreuzen. Dies lässt die einfache Fläche dreidimensional erscheinen.  Für mehr Detail können mehrere überkreuzende Sprites verwendet werden.
Da ein Busch jedoch nicht die gesamte rechteckige Fläche einer Plane überdeckt, werden Pixel nicht verwendet und wären damit besonders auffällig. Mithilfe einer Alpha-Mask lässt sich dies beheben. Eine Alpha Maks ist eine besondere Form von Textur, welche mittels schwarz-weiß Werten die Transparenz der einzelnen Pixel definiert. Das PNG-Dateiformat eignet sich dabei besonders gut für Billboarding, da es einen eigenen Alphakanal besitzt, welcher nicht zusätzlich hinzugefügt werden muss.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Billboarding_Example}
	\caption{Einfaches Billboard}
	\end{figure}

\subsection{Shading}

Das neue Mesh mit sauberer Topologie und geringer Anzahl an Polygonen ist nun für die Game-Engine nutzbar. Doch die geringere Auflösung hat zur Folge, dass damit auch das Detail des gesamten Models reduziert wird. In vielen Fällen bedeutet dies, dass das Model besonders starke Kanten aufweist. Für runde oder weiche Objekte ist dies besonders unvorteilhaft. Spielen mit realistischer Grafik gelingt es dennoch das Objekt richtig darzustellen, obwohl die Polygon-Anzahl deutlich verringert wurde. Dies liegt zum Teil am Smooth Shading.
Allgemein versteht man in der Computergrafik unter Shading die Oberflächeneigenschaften eines 3D-Meshes. Es bezieht sich dabei auf die geworfenen Schatten des Objekts und dessen Reflektions und Lichtbrechungseigenschaften. Dabei soll das Shading bestimmte visuelle Effekte generieren, welche beim wirklichen Licht auftreten. Dazu werden tatsächliche Lichteigenschaften mit komplexen Algorithmen erschaffen. Durch diese Algorithmen lassen sich in Form einer digitalen „Illusion“, der Interpolation, die Oberfläche von Objekten glatter darstellen.
Hieraus wurden deshalb unterschiedliche Techniken entwickelt, die ein 3D-Model unterschiedlich darstellen. Die weitaus simpelsten Techniken sind dabei Flat Shading und Smooth Shading.

\subsection{Flat Shading}

Flat Shading ist die die einfachste Methode einen Gegenstand darzustellen und ist in 3D-Softwares der eingestellte Standard. Dafür wird jedem Face eines Mesh eine einzige Farbe zugewiesen. Diese Farbe wird in Abhängigkeit vom Licht durch den Winkel und dessen Flächennormale (Normalvektor des Faces) bestimmt. Dies führt zu einer zweidimensionalen und daher auch flachen Erscheinung, bei welcher die Kanten zu scharfen Übergängen zwischen den Faces führen. Deswegen erscheint das Objekt bei einer niedrigen Auflösung nicht besonders realistisch. Dafür könnte man mit einer höheren Auflösung kompensieren, wenn die Rechenleistung nicht berücksichtigt wird. Der Vorteil des Flat Shading ist, dass diese Technik besonders einfach und schnell zu rendern ist. Somit ist sie besonders performant.

\subsection{Smooth Shading}

Im Kontrast zum Flat Shading versucht Smooth Shading die Oberfläche eines Objektes glatter darzustellen. Dafür ist die Interpolation notwendig, um die Flächen der Faces zu glätten. Hierzu gibt es zwei übliche Methoden, um dieses Ziel zu erreichen.

\subsubsection{Gouraud Shading}

Henri Gouraud stellte diese Technik erstmalig 1971 vor. Diese Methode konzentrierte sich auf die Vertices eines Polygons und interpoliert basierend auf dem Licht die Oberfläche. Die wichtigsten Parameter für diesen Effekt sind die Vertices, deren Normalvektoren, die Vektoren des Lichtes und auch die Kamerarichtungsvektoren. Damit wird schlussendlich die Farbe der einzelnen Vertices berechnet, welche nur noch interpoliert werden müssen. Die Interpolation ist eine mathematische Technik mittels welcher die Werte zwischen zwei bekannten Werten berechnet werden. Damit ist es nur eine Annäherung an die gegebenen Werte. Die bisherige flache Oberfläche des Objektes ist nun glatt, wobei der Umriss des Objekts weiterhin kantig ist. Gourand Shading braucht dabei eine größere Rechenleistung als Flat Shading, ist jedoch um einiges performanter als einer Erhöhung der Auflösung. Deswegen ist sie standardmäßige Shading-Methode für glatte Oberflächen in Realtime.

\subsubsection{Phong Shading}

4 Jahre nach dem Gouraud Shading wurde die Phong Shading Technik von Bui Tuong Phong vorgestellt. Ähnlich wie bei der bisherigen Methode, liegt die Konzentration erneut bei den Vertices des Objektes. Diesmal werden die Normalen der Vertices berechnet und anhand dieser wird bei der Färbung der zwischen den Normalen der Eckpunkte eine neue interpolierte Normale erschaffen. Die Lichtquelle, Blickrichtung und der Glanz des Materials sind dabei wichtige Komponenten. Das resultierende Smooth Shading führt zu einem realistischeren und akkurateren Ergebnis für die geglättete Oberfläche. Da diese Berechnung jedoch um einiges komplexer ist, ist sie deswegen um einiges rechenintensiver als das Gourand Shading. Daher wird sie selten bei Realtime Rendering benutzt.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Shading}
	\caption{Verschiedene Arten von Shading: Flat - Gouraud - Phong}
	\end{figure}
\cite{_shading}

\subsection{Detail, ohne auf Performance zu vergessen}

Betrachtet man die Welt um sich herum, stellt man fest, dass jedes Objekt mikroskopisch kleine Details hat. Spieleentwickler und 3D-Artist können sich technologisch nicht leisten, jedem Objekt seine atomaren Feinheiten zu geben, jedoch sind essentiellen Merkmale wichtig, um das Objekt als dieses zu erkennen. Betrachtet man z.B. das Gesicht eines alten Mannes, so erkennt man viele Falten, Narben oder raue Hautflecken. Mit dem bisherigen Wissen müsste man all diese Feinheiten modellieren oder sculpten, um den alten Mann als diesen zu erkennen.\cite[3]{_highpoly_to_lowpoly} Die bisherigen Prinzipien erwarten jedoch, dass das Mesh eine möglichst geringste Polygonanzahl besitzt. Die Falten würden dagegen verstoßen, da sie um einiges mehr Polygone benötigen, um richtig auszusehen. Glücklicherweise können die heutigen Materials in 3D-Softwares und Game-Engines mehr als nur Farbwerte nutzen.
Falten und ähnliche Feinheiten geben einem Mesh Tiefe, welche das Objekt dreidimensionaler aussehen lässt. Dafür verwendet man entweder Bump oder Normal Maps.

\begin{figure}[H]
	\centering
"`The bump, normal, and parallax occlusion mapping shaders add 3D depth to an otherwise flat surface. Bump maps are grayscale and display the most limited 3D effect; the others add depth using a color map with lighting information encoded in it. These shaders are all similar in what they accomplish, but depending on the exact code of the shader and the supporting hardware, the effect can range from really cool to absolutely awesome. A basic normal map adds a level of depth deeper than the bump map, but more advanced forms of these shaders add details and behaviors such as self-occlusion, silhouetting, and self-shadowing. Figure 3.23 is a simple visual demonstration of how the shader operates. Because we can calculate the light of the surface for every pixel, we don’t need to include geometry to create shadows and highlights as we did when we lit per polygon. We can now tell the 3D application to treat each and every pixel as if it were reacting to light, as it did when it was on the high-polygon model."'
\cite[96]{_3DGameTextures}
\end{figure}


\subsubsection{Bump-Maps}
Der Ausdruck Bump Map lässt sich in der Realität betrachten, indem man einen Finger über die Oberfläche eines Gegenstandes fährt. Man wird kleine Unebenheiten auf jeder Oberfläche spüren und auch sehen. Für die Computer-Grafik ist die Bump Map notwendig, um diese Unebenheiten zu visualisieren. Dabei handelt es sich nur um eine 2D-Textur aus Grauwerten variierend zwischen 0 (schwarz) und 225 (weiß). Diese Werte stellen die Höheninformation der Textur dar. Mittels komplexer Berechnungen können damit Höhenunterschiede generiert werden, welche aus unterschiedlichen Blickwinkeln betrachtet werden können. Bump Maps ist mittlerweile eine veraltete Methode Detail zu generieren, da sie wegen ihrem kleinen Farbspektrum wenig Informationen beinhalten kann.\cite[86]{_3d_game_textures}

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/BumpNormalMap}
	\caption{Unterschied zwischen Bump-Maps und Normal-Maps}
\end{figure}
\cite{_bumpNormal}

\subsubsection{Normal-Maps}

Mittlerweile ist eine bessere Methode hervorgekommen: Normal Mapping. Genauso wie Bump Mapping zielt Normal Mapping darauf ab, mehr Detail in der Schattierung ohne enorme Rendering-Kosten herauszuholen. Diese orientiert sich nicht an Grauwerten, sondern verwendet das RGB-Farbspektrum. Der Vorteil davon ist, dass mehr Lichtinformationen aus den Farben entnommen werden können, weswegen bessere und realistischere Ergebnisse produziert werden können. Diese RGB-Werte entsprechen jeweils den dementsprechenden X, Y und Z Koordinaten. 
In Essenz ermöglichen Normal Maps bessere Ergebnisse jedoch lassen sie sich per Hand nicht ansatzweise so einfach zeichnen wie Bump Maps. Anstatt sie per Hand zu zeichnen, erlaubt der Fortschritt der Technologie einen automatisierten Generierungsprozess. Adobe Photoshop kann mittlerweile aus ausgewählten Bildern eine Normal Map generieren. Jedoch kommt es zu ungenauen bzw. fehlerhaften Ergebnissen. Diese Methode ist vor allem unvorteilhaft, wenn wir einen weniger generischen Gegenstand, bspw. eine Holzwand, betrachten. Dafür werdet man einen weitaus besseren Vorgang: das Texture Baking

\subsection{Texture Baking}
Texture Baking ist darauf ausgerichtet, den Detailgrad eines Highpoly Meshes auf ein Lowpoly Mesh zu übertragen. Da viele Assets nicht auf generischen Texturen basieren, ist dies nützlich. Auch dann, wenn man ein bestimmtes Aussehen erreichen möchte.\cite[8]{_highpoly_to_lowpoly} Wie bereits erwähnt, braucht man dafür eine hoch aufgelöste und niedrig aufgelöste Version des Meshes. Unterschiedliche Programme wie Substance Painter, Mudbox oder Blender ermöglichen diesen Prozess einfach zu gestalten. Dafür sind lediglich beide Models auf derselben Position notwendig, die UV-Maps beider Objekte und danach folgt die automatisierte Berechnung des Computers. Dieselben Positionen in einem Koordinatensystem sind deswegen notwendig, weil die genauen Lichtberechnung im Verhältnis der Postionen konvertiert, werden müssen. Das Highpoly Mesh schießt dabei Raycasts aus, welche dann die Oberfläche des Lowpoly Meshes treffen. Anhand dieser Treffpunkte wird nun eine Normal Map generiert, welche Lichtinformationen des Highpoly Objekt basierend auf der UV-Map des Lowpoly Mesh baked.

\chapter{Theoretische Implementation in Tricks ´n´ Treats}

Als ein asymmetrisches Couch-Party VR Spiel, gibt es bei Tricks ´n´ Treats einige Faktoren im Bezug zu Performance zu beachten. Das Spiel hat sowohl die Kamera der PC-Spieler als auch die zwei notwendigen Kameras für den VR-Spieler zu rendern, womit jegliche Assets in real-time dreimal gerendert werden müssen. Viele der Performance-Techniken, die erwähnt wurden, können dabei in gemeinsam oder als Ersatz füreinander auftauchen.

\section{Bedenken bei der Implementation}

\subsection{Einschränkung durch den Artstyle}

Tricks ´n´ Treats grafisches Aussehen ähnelt nicht der Realität. Es ist von den modernen und stilisierten Grafiken aus Spielen wie aus Super Mario Odyssey und The Legend of Zelda Breath of the Wild (BotW) inspiriert. Super Mario Odysseys Assets besitzen übertrieben Proportionen und weichen Kanten. BotW nutzt bekanntlich Cell-Shading, um mit nur einfachen Farben und Texturen ein zeitloses Aussehen hervorzubringen. Tricks ´n´ Treats versucht beide diese Eigenschaften zu verbinden und in Lowpoly-Form umzusetzen.

\subsection{Unbedingt Notwendig}

\subsubsection{Mesh Cleanup}

Für Tricks ´n´ Treats wird es unausweichlich sein, die Topologie der Assets zu säubern. Wie bereits erwähnt, bedeutet dies, dass die Mesh-Auflösung reduziert wird. Grund dafür ist, dass es die einfachste Methode ist, um die Performance zu verbessern. Grundlegend würde man dafür jedes Model vor dem UV-Unwrappen und Texturieren erneut auf unnötige Faces oder Edge Loops überprüfen.
Für einfache Objekte, wie bspw. einen Eimer, eignet es sich besonders, sofort mit so wenig Geometrie wie möglich anzufangen und nur wenn notwendig mehr Detail hinzufügen. Im Falle der spielbaren Charaktere der PC-Spieler würde man jedoch umgekehrt vorgehen. Die Charaktere besitzen weiche Kanten, weswegen es einfacher ist, die Auflösung im Nachhinein hinunter, anstatt hinaufzuskalieren.
Der offensichtliche Vorteil des Mesh-Cleanups ist, dass im Spiel weniger Faces gerendert werden müssen. Deswegen wird dieser Prozess unvermeidlich sein, da es technisch keine Probleme bereitet und einfach implementierbar ist.

\subsubsection{Smooth Shading}

Jedoch erhalten wir damit ein visuelles Problem, da die Assets nun kantig sind. Da Tricks ´n´ Treats Assets stilistisch weiche Kanten haben soll, kann das Mesh-Cleaning nicht allein eingesetzt werden. Deswegen sollte man zusätzlich jedes 3D-Asset „smooth-shaden“. Damit sind weiche Kanten und Formen möglich, ohne eine enorme Rendering-Last zu werden. Diese beiden Methoden werden damit gemeinsam die Essenz der Asset Optimierung für Tricks ´n´ Treats bilden, da sie keine wirklichen Nachteile besitzen.

\subsection{Hat die Methode einen Sinn?}

\subsubsection{LODs und Billboarding}

Aufbauend auf der Mesh Auflösung würde sich das Unity LOD-System (Level of Detail) eignen. Das System verwendet dafür unterschiedliche Models mit unterschiedlichem Detailgrad, welche in Abhängigkeit von der Entfernung der Kamera ausgetauscht werden. Befindet sich ein Spieler nahe an dem Objekt, so wird der LOD das hochaufgelöste Model gerendert. Je weiter weg sich der Spieler befindet, desto weniger Auflösung ist nötig, um denselben Gegenstand darzustellen. Für die 3D-Assets würde dies bedeuten, dass mehrere Versionen vom selben Objekt erstellt werden müssen.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/LODs}
	\caption{Verschiedene Auflösungen des selben Meshes}
\end{figure}

Das Prinzip des Billboarding würde sich kombiniert mit LODs zusätzlich für die Performance eignen. Dies würde bedeuten, dass anstelle eines Meshes zwei oder mehrere überlappende Bilder verwendet werden. Anstelle eines niedrigdetaillierten Models würde man als niedrigste LOD-Stufe das Bild verwenden und könnte damit immense Rendering-Kosten sparen. Das liegt daran, dass nur noch ein oder zwei Faces anstatt einem gesamten Model gerendert werden müssen.
Diese Methode könnte an sich für bessere Performance sorgen und die Grafikarte entlasten. Die Grafikarte kann jedoch nur deswegen entlastet werden, weil die CPU dafür sorgt, dass die LOD-Stufen ausgetauscht werden. Dies führt jedoch zu einer größeren Rechenlast für die CPU. Da Tricks ´n´ Treats drei Kameras hat, würde sich die Rechenlast enorm vergrößern und bestehende Gleichgewicht zwischen CPU und GPU würde entarten. Die GPU wäre, indem fall unterfordert, die CPU hingegen überfordert, wodurch die CPU alle aufgestauten Berechnungen zuerst beenden müsste. Damit gebe es um einiges mehr Nachteile als Vorteile im Falle von Tricks ´n´ Treats.

\subsubsection{Billboarding in Tricks ´n´ Treats}
Billboarding allein würde in Tricks ´n´ Treats keinen wirklichen Vorteil bieten, da diese Technik hauptsächlich für Foliage in Spielen genutzt wird. Tricks ´n´ Treats besitzt keine wirklichen Pflanzen oder Büsche. Möglicherweise würde man Billboarding für gewisse dekorative Assets auf der Strecke verwenden, wenn es sich nur um ein PC-Spiel handeln würde. Da der VR-Spieler jedoch die Assets auf der Strecke von überall sehen kann, würde der visuelle Effekt von Billboarding nicht zustande kommen. Billboarding würde damit immer noch performant sein, jedoch nicht das Ziel erfüllen, für welches es optimiert wurde. 

\subsection{Texturing in Tricks ´n´ Treats}

\subsubsection{Handgemalte Texturen vs. einfache Farben}

Die Assets in Tricks ´n´ Treats werden größtenteils Textur-Atlasse verwenden um, Speicherplatz als auch Draw Calls zu sparen. Dabei werden diese Texturen meist aus einfachen Farben bestehen oder per Hand gezeichnet. Assets, die nicht im Hintergrund stehen oder besonders klein sind, brauchen keine gezeichnete Textur, da es nicht auffällt, wenn sie simpel texturiert werden, wodurch zusätzlich an Texturauflösung gespart weden kann. Daher würden die spielbaren Charaktere oder die Assets für die Strecke nur einfach texturiert werden. Dabei liegt ein großer Fokus darauf, dass die UV-Map aller Objekte so performant wie möglich genutzt wird, damit man die Auflösung der Textur noch weiter reduzieren kann.
Die Assets im VR-Raum, wie bspw. Items und der Arbeitsplatz des VR-Spielers können hingegen handgezeichnete Texturen verwenden. Dekorative Objekte können dennoch auf einer einzigen Textur texturiert werden. Hierbei gilt es besonders auf die Qualität der UV-Map zu achten.

\subsubsection{Atlassing in Tricks ´n´ Treats}

Das Problem an Textur Atlassen ist, dass diese Methode um einiges Zeitintensiver ist als für jedes Objekt eine einzelne Textur zu erstellen. Das liegt vor allem daran, dass trotz der gruppieren aller UV-Maps eine gute Organisation für die Atlasse gebraucht wird. Bspw. sollten die Item-Texturen von den Charakter-Texturen getrennt ein. Auch mit guter Organisation, wird um einiges mehr Zeit gebraucht, um die Texturen zu bearbeiten. Der notwendige Zeitaufwand sollte es doch im Falle von Tricks ´n´ Treats wert sein, da man hiermit an Anzahl an Texturen, Rendering Kosten, Speicherplatz und Auflösung sparen kann.

\subsection{Texture Baking als Alternative}

Eine Alternative zur LOD-Methode ist das Texture-Baking. Diese könnte zusätzlich zu den Texturen eingesetzt werden, um die Faceanzahl zu reduzieren. Einkerbung in Holz oder die Rinnen einer Ziegelsteinwand könnten mithilfe dieser Methode simpel dargestellt werden. Ähnlich wie bei LODs werden dafür Varianten von demselben Asset benötigt. Im Falle vom Texture Baking, braucht man eine Highpoly und eine Lowpoly Version vom selben Mesh. Die Details des Highpoly-Meshes werden schließlich auf einer Normal-Map generiert und übertragen. Nun kann das das Highpoly-Mesh verworfen werden und gegen das Lowpoly-Mesh ausgetauscht werden, welches mit der angehängten Normal-Map beinahe identisch aussehen sollte.

\subsubsection{Normal Maps oder Textur Atlasse}

Obwohl Normal-Maps die Anzahl an benötigten Faces reduzieren, sind sie nicht immer vorteilhaft. Wird ein oder mehrere Textur Atlasse benutzt, so muss man für jedes Objekt eine Highpoly und Lowpoly Verion erstellen, diese UV-Unwrappen und schließlich Texture Baken. Dies ist ein besonders langwieriger Prozess, welcher manuell ausgeführt werden muss. Bei einzelnen Objekten mit eigener Textur würde sich Texture Baking besser eignen als bei Atlassen. Somit sind Normal-Maps in Tricks ´n´ Treats meist unpraktisch, außer man würde die Atlasse durch einzelne Texturen austauschen.

\chapter{Praktische Implementation in Tricks ´n´ Treats}

\section{Endresultat}

\subsection{Entwicklung des Arbeitsprozesses}

Das tatsächliche Implementieren verlief nicht auf einem linearen Weg. Oftmals wurden die Prioritäten der Assets neu bewertet und hinsichtlich auch die Performance Optimierung. Am Anfang des Projektes waren viele der Methoden nur ein grober Gedanke, da viele der visuellen Ideen und Entscheidung erst mit der weiterführenden Entwicklung des Projektes entschieden worden sind.
Daraus erschloss sich, dass manche Methoden zur Performance Optimierung vollkommen unpraktisch waren oder noch genauer durchgeführt wurden.

\section{Erwartete Ergebnisse}

\subsection{Mesh Cleaning in Tricks ´n´ Treats}
Die Verbesserung und Optimierung der Mesh-Topologie war wie erwartet am einfachsten zu implementieren und einzusetzen. Neben dem tatsächlichen Modellieren beruhte ein überschaubar großer Teil des Arbeitsaufwandes alle Assets zu optimieren.
Dabei wurde festgestellt, dass dieser Prozess auf zwei Arten umgesetzt wurde. Vor der Implementation war die Annahme, dass unwichtige Objekte mit wenig Geometrie anfangen und bei Bedarf mehr Detail erhalten würden. Assets wie bspw. die Charaktere hingegen fingen mit einem detaillierten Mesh an und wurden dann optimiert. Obwohl dieses Prinzip angewendet wurde, gab es beim Modellieren ein weiteres Kriterium zu beachten. Abhängig davon, ob es sich um ein organisches Objekt handelte oder nicht, wurde die „Downscaling“ Methode verwendet. Der Grund dafür ist, dass Assets mit weichen Kanten auf diese Art schneller modelliert wurden und auch besser aussahen.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Meshcleaning_tnt}
	\caption{Vergleich: 1200 Faces vs 6200 Faces}
\end{figure}

\subsubsection{Unsichtbare Faces und Clipping}

Um die Performance der Models noch weiter zu verbessern, wurde zusätzlich Faces gelöscht, welche sich schneiden (Clipping) oder für die Spieler nicht sichtbar waren. Diese Methode war beispielsweise für die Charaktere und dekorative Assets in besonders Vorteilhaft, da man überschüssige Faces somit entfernen kann.
Betrachtet man den Hasen-Charakter, so stellt man fest, dass der Kopf, die Ohren und der Torso nicht aus einem einzigen Objekt bestehen. Diese drei Körperteile wurden einzeln erstellt und zusammengesteckt. Viele Faces würden deswegen nie für den Spieler sichtbar sein, weswegen man sie entfernen kann. Da alle Charaktere auf Snowboards stehen, brauchen sie auch keine Faces an ihren Fußsohlen.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/Clipping_tnt}
	\caption{Unötige Faces}
\end{figure}

Ebenso lassen sich von vielen Objekten die Boden-Faces löschen, da diese auch nicht sichtbar sind. Töpfe, Tischbeine oder auch Bücher, haben deswegen keine Faces am Boden und Rücken.
Bei einem einzelnen Objekt würde sich dieser Arbeitsaufwand wahrscheinlich nicht auszahlen, weil meistens nur sehr wenige Faces gelöscht werden. Tricks n’ Treats besteht jedoch aus einer großen Szene mit vielen Objekten, weshalb es sich in diesem Fall auszahlt, alle unsichtbaren Faces zu löschen, obwohl es etwas zeitaufwendiger ist. Auf diese Art wurden ca. 1.000 Faces gelöscht, wodurch man ungefähr 3.000 Faces weniger rendern musste.

\subsection{Smooth Shading in Tricks ´n´ Treats}

Da die Assets in Tricks n’Treats eine niedrige Mesh-Auflösung besitzen, hatten alle Objekte ein sehr kantiges Aussehen. Um dies zu verhindern, wurde wie erwartet Smooth-Shading verwendet. Obwohl das Projekt eine große Anzahl an Assets hatte, war diese Methode dennoch um einiges weniger rechenintensiv als allen Assets ein detaillierteres Mesh zu geben.

\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/SmoothShading_tnt}
	\caption{Vergleich: Flat Shading vs. Smooth Shading}
\end{figure}

\subsubsection{Auto Smooth – Das Beste aus beiden Welten}

Das Ziel dieser Shading-Einstellung ist es, für ein glatte Kanten zu sorgen. Dabei entsteht jedoch das Problem, dass ein Objekt sowohl weiche als auch scharfe Kanten haben kann. Glücklicherweise ermöglicht die 3D-Software Blender, sowohl weiche als auch scharfe Kanten zu haben. Die Auto Smooth Funktion ermöglicht es manuell einzustellen, ab welcher Neigung die Edges weich sein sollen. 
Zusätzlich ermöglicht Blender, einzelne Edges auszuwählen und scharf zu rendern. Diese Einstellungen gehen beim Importieren in Unity nicht verloren und benötigt keinen großen Zeitaufwand.

\section{Texturieren – Die Evolution}

Vor allem beim Texturieren gab es einige Änderungen, welche von der eigentlichen Idee abschweifen. Viele der geplanten Ideen wurden wegen Zeitmangel oder auch Performancegründen komplett verworfen. Eine wichtige Design-Entscheidung, welche ungefähr in der Mitte der Projektentwicklung getroffen wurde, war es nur noch einfache Farben für alle 3D-Assets zu verwenden. Da die Erstellung einer einzelnen Textur viel Zeit in Anspruch nahm, wurde sicherheitshalber beschlossen, nur Farben zu verwenden. Damit wurde zusätzlich auch indirekt Performance verbessert, da es nun um einiges weniger Texturen gab, womit weniger Speicherplatz genutzt wurde und es weniger zu rendern gab. Zusätzlich zu dem ganzen wurden sämtlich Texturen mit einem Cell-Shader gerendert.
Diese Änderung war ebenfalls der Grund, warum kein Texture Baking oder Normal Maps verwendet wurden, da die Normal Maps das simple Aussehen des Cell-Shaders nicht komplementierten.

\subsection{Textur Paletten}

Texture Atlassing ist die hauptsächliche Methode zum Texturieren in Tricks n’Treats. Insgesamt werden nur drei Texturen verwendet, welche alle für eine jeweils spezifische Gruppe an Assets verwendet werden. 
Man unterscheidet zwischen:
Raum-Textur: Diese Textur ist für alle Assets im VR-Raum zuständig
Charakter-Textur: Diese Textur ist für die spielbaren Charaktere zuständig
Asset-Textur: Diese Textur ist für alle Assets auf der Strecke zuständig
Diese Texturen sind jedoch eigentlich nur eine simple Farbpalette und bestehen nur aus wenigen Pixeln. Da alle Assets nur eingefärbte Faces haben, muss man nicht großartig auf die UV-Map und Textur achten. Da Eine Farbe eigentlich nur ein einziger Farbwert ist, kann dieser in einem einzigen Pixel dargestellt werden. Die UV-Map aller Objekte kann deswegen automatisch unwrapped werden, wobei sich die einzelnen Faces der UV-Map dann in einem einzelnen Farb-Pixel der Palette befinden. Die Raum-Textur ist dabei die größte Textur mit insgesamt 30x30 Pixeln.
Mit dieser Methode fällt das UV-Mapping als auch Texturieren so gut wie weg und bietet dennoch die Vorteile eines Textur-Atlasses mit nur sehr wenig benötigtem Speicherplatz. Das einzige Problem, welches bei Technik vorkommt, ist eine etwas langwierige Veränderung. Es ist oftmals vorgekommen, dass mehrere Objekte denselben Farb-Pixel teilten. Wenn eine bestimmte Farbe für ein Asset nicht angemessen war und die Farbe verändert wurde, so wurde die Farbe für mehrere Assets gleichzeitig verändert, weswegen man nun allen betroffenen Assets neue Farben zuweisen musste.
\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{images/memic/ColorPalette_tnt}
	\caption{Textur Palette und Charaktere}
\end{figure}
Eine gute Erweiterung dieser Methode, wäre es wahrscheinlich, eine vorzeitliche bessere Organisation und auch Kategorisierung der Assets. Damit hätte man bspw. die Asset-Palette und Raum-Palette auf nur eine Textur komprimieren können. Zusätzlich könnte darauf geachtet werden können, dass eine Farbe nicht mehrmals in derselben Textur vorkommt, oder dass eine Reihe an Pixeln nur für ein Objekt zuständig ist. Nachdem alle Assets texturiert sind, hätte man außerdem noch die Textur auf die genaue Anzahl an verwendeten Pixeln reduzieren können.

\section{Rückblick}

Mit dem Ende des Projektes lassen sich im Nachhinein manche Optimierungs-Methoden erneut betrachten. Das allgemein größte Problem während der Projekt-Ausführung ist ein Mangel an Organisation und eine Überschätzung des benötigten Zeitaufwandes. LODs und Billboards als Methoden, um für eine bessere Performance zu sorgen, sind jedoch nicht darauf ausgelegt, als eine Kombination aus PC und VR-Spiel zu funktionieren. Es wäre weitaus wichtiger gewesen, das Mergen von Objekten mehr zu beachten. Da jedes Assets gerendert werden muss, hätte man weniger Rendering-Aufrufe gebraucht, wenn viele kleinere Objekte zu einem einzigen Mesh zusammengetan wären.\cite[S.154]{_unity_game_optimization}

